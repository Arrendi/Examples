---
title: "CalcBehavior"
output: html_document
---

An attempt to semi-theoretically analyze the efficacy of different nested training
methods.  The first step is estimating y conditioned on group, the second is a 
glm() model on top of this estimate.  The nested model usually gives trouble as the
group variable can hide degrees of freedom and cause over-fitting.

```{r}
library('polynom')
library('ggplot2')


# y_i = 1 with probability x, 0 otherwise
# k = # of groups
# n = # of examples
# B logistic regresion solution to y ~ 0 + est
# est formed different ways
set.seed(23225)
k <- 2
probOn <- polynomial(c(0,1))
gGroups <- paste('g',1:k,sep='')
d <- data.frame(group=rep(gGroups,3),
                y=FALSE,
                stringsAsFactors=FALSE)
n <- nrow(d)
dTest <- data.frame(group=gGroups,
                    stringsAsFactors=FALSE)

#' compute the direct expected value of y per group
#'
#' @param d data frame with y and group columns
#' @return named vector with grouped y-means
empiricalEst <- function(d) {
  d$one <- 1.0
  num <- aggregate(y~group,data=d,FUN=sum)
  den <- aggregate(one~group,data=d,FUN=sum)
  if(!all(all.equal(num$group,den$group)==TRUE)) {
    stop("name mismatch")
  }
  est <- num$y/den$one
  names(est) <- num$group
  est
}

#' compute the jackknifed expected value of y per group
#'
#' @param d data frame with y and group columns
#' @param jackDenom denominator of current observation to pull off in estimate, 1 is standard jackknife, 2 is one half jackknife
#' @return named vector with jackknifed grouped y-means
jackknifeEst <- function(d,jackDenom) {
  d$one <- 1.0
  num <- aggregate(y~group,data=d,FUN=sum)
  numM <- num$y
  names(numM) <- num$group
  numV <- numM[d$group]
  den <- aggregate(one~group,data=d,FUN=sum)
  denM <- den$one
  names(denM) <- den$group
  denV <- denM[d$group]
  if(!all(all.equal(num$group,den$group)==TRUE)) {
    stop("name mismatch")
  }
  v <- as.numeric((numV-d$y/jackDenom)/(denV-1/jackDenom))
  v[is.na(v)|is.infinite(v)|is.nan(v)] <- 0
  v
}

#' Fit a glm() on top of the dEstimate column to the d$y column, then apply this model to dTest
#'
#' Simulates the second stage of a 2-stage modeling process.
#' @param d data frame with y column
#' @param dEst numeric with one sub-model prediction per row of d
#' @param dTest frame to score on has group and est columns
#' @return dTest predictions
estimateExpectedPrediction <- function(d,dEst,dTest) {
  # catch cases unsafe for glm
  if(all(d$y) || all(!d$y) || 
     ((max(dEst)-min(dEst))<=1.0e-5)) {
    return(dTest$est)
  }
  d$est <- dEst
  m <- glm(y~0+est,data=d,family=binomial(link='logit'))
  predict(m,newdata=dTest,type='response')
}

ys <- expand.grid( rep( list(0:1), n))==1
nPredExpectedMin <- 0
jPredExpectedMin <- 0
jPredExpected2Min <- 0
nPredExpectedMean <- 0
jPredExpectedMean <- 0
jPredExpected2Mean <- 0
nPredExpectedMax <- 0
jPredExpectedMax <- 0
jPredExpected2Max <- 0
for(ii in seq_len(nrow(ys))) {
  y <- as.logical(ys[ii,])
  d$y <- y
  py <- probOn^(sum(y))*(1-probOn)^(length(y)-sum(y))
  empEstD <- empiricalEst(d)
  dTest$est <- as.numeric(empEstD[dTest$group])
  nPred <- estimateExpectedPrediction(d,empEstD[d$group],dTest)
  nPredExpectedMin <- nPredExpectedMin + min(nPred)*py
  nPredExpectedMean <- nPredExpectedMean + mean(nPred)*py
  nPredExpectedMax <- nPredExpectedMax + max(nPred)*py
  jPred <- estimateExpectedPrediction(d,jackknifeEst(d,1),dTest)
  jPredExpectedMin <- jPredExpectedMin + min(jPred)*py
  jPredExpectedMean <- jPredExpectedMean + mean(jPred)*py
  jPredExpectedMax <- jPredExpectedMax + max(jPred)*py
  jPred2 <- estimateExpectedPrediction(d,jackknifeEst(d,2),dTest)
  jPredExpected2Min <- jPredExpected2Min + min(jPred2)*py
  jPredExpected2Mean <- jPredExpected2Mean + mean(jPred2)*py
  jPredExpected2Max <- jPredExpected2Max + max(jPred2)*py
}

print('naive prediction')
print(nPredExpectedMin)
print(nPredExpectedMean)
print(nPredExpectedMax)

print('jackknife prediction')
print(jPredExpectedMin)
print(jPredExpectedMean)
print(jPredExpectedMax)

print('jackknife 2 prediction')
print(jPredExpectedMin)
print(jPredExpectedMean)
print(jPredExpectedMax)

print('ideal prediction')
print(probOn)

plotD <- data.frame(x=seq(0,1,by=0.01),
                    stringsAsFactors = FALSE)
plotD2 <- plotD
plotD2$what <- 'naive prediction'
plotD2$expectedMin <- as.function(nPredExpectedMin)(plotD$x)
plotD2$expectedMean <- as.function(nPredExpectedMean)(plotD$x)
plotD2$expectedMax <- as.function(nPredExpectedMax)(plotD$x)
plotD3 <- plotD
plotD3$what <- 'jackknife prediction'
plotD3$expectedMin <- as.function(jPredExpectedMin)(plotD$x)
plotD3$expectedMean <- as.function(jPredExpectedMean)(plotD$x)
plotD3$expectedMax <- as.function(jPredExpectedMax)(plotD$x)
plotD4 <- plotD
plotD4$what <- 'jackknife 2 prediction'
plotD4$expectedMin <- as.function(jPredExpected2Min)(plotD$x)
plotD4$expectedMean <- as.function(jPredExpected2Mean)(plotD$x)
plotD4$expectedMax <- as.function(jPredExpected2Max)(plotD$x)
plotD <- rbind(plotD2,plotD3,plotD4)

ggplot(data=rbind(plotD2,plotD3),mapping=aes(x=x,
                                             y=expectedMean,
                                             ymin=expectedMin,ymax=expectedMax,
                              color=what,fill=what)) +
  geom_ribbon(alpha=0.5) +
  geom_abline() + 
  geom_line() +
  coord_fixed() +
  ggtitle(paste('predictions, n=',n))

ggplot(data=rbind(plotD3,plotD4),
       mapping=aes(x=x,
                   y=expectedMean,
                   ymin=expectedMin,ymax=expectedMax,
                              color=what,fill=what)) +
  geom_ribbon(alpha=0.5) +
  geom_abline() + 
  geom_line() +
  coord_fixed() +
  ggtitle(paste('predictions, n=',n))

plotDA <- rbind(plotD2,plotD3,plotD4)
plotDA$expectedMaxError <- pmax(abs(plotDA$x-plotDA$expectedMin),
                               abs(plotDA$expectedMax-plotDA$x))
ggplot(data=plotDA,mapping=aes(x=x,y=expectedMaxError,
                              color=what,fill=what)) +
  geom_line() +
  ggtitle(paste('max error in estimates, n=',n))



plotR <- data.frame(x=seq(0,1,by=0.01),
                    stringsAsFactors = FALSE)
plotR1ratio <- as.function(probOn)(plotR$x)
plotR2 <- plotR
plotR2$what <- 'naive prediction'
plotR2$expectedRatioMin <- as.function(nPredExpectedMin)(plotR$x)/plotR1ratio
plotR2$expectedRatioMean <- as.function(nPredExpectedMean)(plotR$x)/plotR1ratio
plotR2$expectedRatioMax <- as.function(nPredExpectedMax)(plotR$x)/plotR1ratio
plotR3 <- plotR
plotR3$what <- 'jackknife prediction'
plotR3$expectedRatioMin <- as.function(jPredExpectedMin)(plotR$x)/plotR1ratio
plotR3$expectedRatioMean <- as.function(jPredExpectedMean)(plotR$x)/plotR1ratio
plotR3$expectedRatioMax <- as.function(jPredExpectedMax)(plotR$x)/plotR1ratio
plotR4 <- plotR
plotR4$what <- 'jackknife 2 prediction'
plotR4$expectedRatioMin <- as.function(jPredExpected2Min)(plotR$x)/plotR1ratio
plotR4$expectedRatioMean <- as.function(jPredExpected2Mean)(plotR$x)/plotR1ratio
plotR4$expectedRatioMax <- as.function(jPredExpected2Max)(plotR$x)/plotR1ratio

ggplot(data=rbind(plotR2,plotR3),
       mapping=aes(x=x,
                   y=expectedRatioMean,
                   ymin=expectedRatioMin,ymax=expectedRatioMax,
                   color=what,fill=what)) +
  geom_ribbon(alpha=0.5) +
  geom_line() + 
  geom_hline(yintercept=1) +
  ggtitle(paste('prediction ratios, n=',n))

ggplot(data=rbind(plotR3,plotR4),
       mapping=aes(x=x,
                   y=expectedRatioMean,
                   ymin=expectedRatioMin,ymax=expectedRatioMax,
                   color=what,fill=what)) +
  geom_ribbon(alpha=0.5) +
  geom_line() +
  geom_hline(yintercept=1) +
  ggtitle(paste('prediction ratios, n=',n))


plotRA <- rbind(plotR2,plotR3,plotR4)
plotRA$expectedMaxAlbsLogRelError <- pmax(abs(log(plotRA$expectedRatioMin)),
                               abs(log(plotRA$expectedRatioMax)))
ggplot(data=plotRA,
       mapping=aes(x=x,
                   y=expectedMaxAlbsLogRelError,
                   color=what,fill=what)) +
  geom_line() +
  ggtitle(paste('prediction expected abs log error ratio, n=',n))

```

