---
title: "CodingExample"
author: "Win-Vector LLC"
date: "September 30, 2015"
output: html_document
---


```{r, echo=FALSE, results='hide', warning=FALSE}
source('utils.R')
source('modelCat.R')
source('mkExample.R')
# devtools::install_github("WinVector/WVPlots")
library("WVPlots")
# devtools::install_github('WinVector/vtreat')
library('vtreat')

runAll <- TRUE
debug <- FALSE
cl <- NULL

set.seed(232567)
vplan <- list(designVar('x1',10),
              designVar('x2',10),
              designVar('x3',10),
              designVar('x4',10),
              designVar('x5',10),
              designVar('x6',10),
              designVar('x7',10),
              designVar('x8',10),
              designVar('x9',10),
              designVar('x10',10),
              designNoiseVar('n1',500),
              designNoiseVar('n2',500),
              designNoiseVar('n3',500),
              designNoiseVar('n4',500),
              designNoiseVar('n5',500),
              designNoiseVar('n6',500),
              designNoiseVar('n7',500),
              designNoiseVar('n8',500),
              designNoiseVar('n9',500),
              designNoiseVar('n10',500),
              designNoiseVar('n11',500),
              designNoiseVar('n12',500),
              designNoiseVar('n13',500),
              designNoiseVar('n14',500),
              designNoiseVar('n15',500),
              designNoiseVar('n16',500),
              designNoiseVar('n17',500),
              designNoiseVar('n18',500),
              designNoiseVar('n19',500),
              designNoiseVar('n20',500),
              designNoiseVar('n21',500),
              designNoiseVar('n22',500),
              designNoiseVar('n23',500),
              designNoiseVar('n24',500),
              designNoiseVar('n25',500),
              designNoiseVar('n26',500),
              designNoiseVar('n27',500),
              designNoiseVar('n28',500),
              designNoiseVar('n29',500),
              designNoiseVar('n30',500))
yVars <- c('yCat','yNumeric')
yName <- 'yCat'

dTrain <- generateExample(vplan,2000)  # Training set
vars <- setdiff(colnames(dTrain),yVars)
dCal <- generateExample(vplan,2000)   # Used to pick sigma
dTest <- generateExample(vplan,10000)  # Pure holdout test
```

```{r, echo=FALSE, results='hide', warning=FALSE}
cl <- NULL
if(runAll && (!debug)) {
  cl <- parallel::makeCluster(parallel::detectCores())
}
```

```{r, echo=FALSE, results='hide', warning=FALSE}
mkWorker1 <- function() {
  bindToEnv(environment(),
            yName,
            yVars,
            dTrain,
            vars,
            dCal,
            errorRate,
            rlaplace,
            noiseCount,
            conditionalCounts,
            listLookup,
            bayesCode,
            trainCoder,
            codeFrame,
            trainBayesCoder,
            countCode,
            trainCountCoder)
  function(sigma) {
    cCoder <- trainCountCoder(dTrain,yName,vars,sigma)
    dTrainC <- cCoder$codeFrame(dTrain)
    dCalC <- cCoder$codeFrame(dCal)
    varsC <- setdiff(colnames(dTrainC),yVars)
    formulaC <- paste(yName,paste(varsC,collapse=' + '),sep=' ~ ')
    modelC <- glm(formulaC,data=dTrainC,family=binomial(link='logit'))
    dCalC$pred <- predict(modelC,newdata=dCalC,type='response')
    scoreC <- errorRate(dCalC$pred,dCalC[[yName]])
    bCoder <- trainBayesCoder(dTrain,yName,vars,sigma)
    dTrainB <- bCoder$codeFrame(dTrain)
    dCalB <- bCoder$codeFrame(dCal)
    varsB <- setdiff(colnames(dTrainB),yVars)
    formulaB <- paste(yName,paste(varsB,collapse=' + '),sep=' ~ ')
    modelB <- glm(formulaB,data=dTrainB,family=binomial(link='logit'))
    dCalB$pred <- predict(modelB,newdata=dCalB,type='response')
    scoreB <- errorRate(dCalB$pred,dCalB[[yName]])
    list(scoreC=scoreC,scoreB=scoreB,sigma=sigma)
  }
}

cSigmaBest = 0
bSigmaBest = 0

if(runAll) {
  sigmaTargets <- (seq_len(21)-1)
  worker <- mkWorker1()
  if(!is.null(cl)) {
    results <- parallel::parLapplyLB(cl,sigmaTargets,worker)
  } else {
    results <- vector(mode='list',length=length(sigmaTargets))
    for(ii in seq_len(length(sigmaTargets))) {
      results[[ii]] <- worker(sigmaTargets[[ii]])
    }
  }
  
  bestC = Inf
  bestB = Inf
  for(res in results) {
    sigma <- res$sigma
    scoreC <- res$scoreC
    scoreB <- res$scoreB
    if(scoreC<bestC) {
      bestC <- scoreC
      cSigmaBest <- sigma
    }
    if(scoreB<bestB) {
      bestB <- scoreB
      bSigmaBest <- sigma
    }
  }
}
```


```{r}
for(cSigma in sort(unique(c(0,cSigmaBest)))) {
  print(paste('count model, sigma=',cSigma))
  cCoder <- trainCountCoder(dTrain,yName,vars,cSigma)
  dTrainC <- cCoder$codeFrame(dTrain)
  dTestC <- cCoder$codeFrame(dTest)
  varsC <- setdiff(colnames(dTrainC),yVars)
  formulaC <- paste(yName,paste(varsC,collapse=' + '),sep=' ~ ')
  modelC <- glm(formulaC,data=dTrainC,family=binomial(link='logit'))
  dTrainC$pred <- predict(modelC,newdata=dTrainC,type='response')
  print(paste('train errorRate',errorRate(dTrainC$pred,dTrainC[[yName]])))
  print(WVPlots::ROCPlot(dTrainC,'pred',yName,
                         paste('count model train, sigma=',cSigma)))
  dTestC$pred <- predict(modelC,newdata=dTestC,type='response')
  print(paste('test errorRate',errorRate(dTestC$pred,dTestC[[yName]])))
  print(WVPlots::ROCPlot(dTestC,'pred',yName,
                         paste('count model test, sigma=',cSigma)))
}
```



```{r}
for(bSigma in sort(unique(c(0,bSigmaBest)))) {
  print(paste('Bayes model, sigma=',bSigma))
  bCoder <- trainBayesCoder(dTrain,yName,vars,bSigma)
  dTrainB <- bCoder$codeFrame(dTrain)
  dTestB <- bCoder$codeFrame(dTest)
  varsB <- setdiff(colnames(dTrainB),yVars)
  formulaB <- paste(yName,paste(varsB,collapse=' + '),sep=' ~ ')
  modelB <- glm(formulaB,data=dTrainB,family=binomial(link='logit'))
  dTrainB$pred <- predict(modelB,newdata=dTrainB,type='response')
  print(paste('train errorRate',errorRate(dTrainB$pred,dTrainB[[yName]])))
  print(WVPlots::ROCPlot(dTrainB,'pred',yName,
                         paste('Bayes model train, sigma=',bSigma)))
  dTestB$pred <- predict(modelB,newdata=dTestB,type='response')
  print(paste('test errorRate',errorRate(dTestB$pred,dTestB[[yName]])))
  print(WVPlots::ROCPlot(dTestB,'pred',yName,
                         paste('Bayes model test, sigma=',bSigma)))
}
```

```{r}
print('Bayes model, jacknifed')
bCoder <- trainBayesCoder(dTrain,yName,vars,0)
# dTrainB <- bCoder$codeFrame(dTrain)
dTrainB <- jackknifeBayesCode(dTrain,yName,vars)
dTestB <- bCoder$codeFrame(dTest)
varsB <- setdiff(colnames(dTrainB),yVars)
formulaB <- paste(yName,paste(varsB,collapse=' + '),sep=' ~ ')
modelB <- glm(formulaB,data=dTrainB,family=binomial(link='logit'))
dTrainB$pred <- predict(modelB,newdata=dTrainB,type='response')
print(paste('train errorRate',errorRate(dTrainB$pred,dTrainB[[yName]])))
print(WVPlots::ROCPlot(dTrainB,'pred',yName,
                       'Bayes model train, jackknifed'))
dTestB$pred <- predict(modelB,newdata=dTestB,type='response')
print(paste('test errorRate',errorRate(dTestB$pred,dTestB[[yName]])))
print(WVPlots::ROCPlot(dTestB,'pred',yName,
                       'Bayes model test, jackknifed'))
```

```{r}
print('count model, jackknifed')
cCoder <- trainCountCoder(dTrain,yName,vars,0)
# dTrainC <- cCoder$codeFrame(dTrain) # naive coding, fails
dTrainC <- jackknifeCountCode(dTrain,yName,vars)
dTestC <- cCoder$codeFrame(dTest)
varsC <- setdiff(colnames(dTrainC),yVars)
formulaC <- paste(yName,paste(varsC,collapse=' + '),sep=' ~ ')
modelC <- glm(formulaC,data=dTrainC,family=binomial(link='logit'))
dTrainC$pred <- predict(modelC,newdata=dTrainC,type='response')
print(paste('train errorRate',errorRate(dTrainC$pred,dTrainC[[yName]])))
print(WVPlots::ROCPlot(dTrainC,'pred',yName,
                       'count model train, jackknifed'))
dTestC$pred <- predict(modelC,newdata=dTestC,type='response')
print(paste('test errorRate',errorRate(dTestC$pred,dTestC[[yName]])))
print(WVPlots::ROCPlot(dTestC,'pred',yName,
                       'count model test, jackknifed'))
```


```{r}
print("vtreat split model")
pruneSig = 0.05

print("working vtreat split model")
mTitle <- 'vtreat split model'
isTrain <- runif(nrow(dTrain))<=0.5
dTrainDT <- dTrain[isTrain,]
dTrainDC <- dTrain[!isTrain,]
treatments <- vtreat::designTreatmentsC(dTrainDC,vars,yName,TRUE,
                                        rareSig=0.3,
                                        smFactor=5.0,
                                        minFraction=2.0,
                                        verbose=FALSE,
                                        parallelCluster=cl)
dTrainV <- vtreat::prepare(treatments,dTrainDT,pruneSig=pruneSig,
                           parallelCluster=cl)

# print(treatments$scoreFrame)
varsV <- intersect(colnames(dTrainV),
                   treatments$scoreFrame$varName[treatments$scoreFrame$sig<pruneSig])
print(varsV)
dTestV <- vtreat::prepare(treatments,dTest,pruneSig=pruneSig,
                          varRestriction=varsV,
                          parallelCluster=cl)
formulaV <- paste(yName,paste(varsV,collapse=' + '),sep=' ~ ')
modelV <- glm(formulaV,data=dTrainV,family=binomial(link='logit'))
dTrainV$pred <- predict(modelV,newdata=dTrainV,type='response')
print(paste('train errorRate',errorRate(dTrainV$pred,dTrainV[[yName]])))
print(WVPlots::ROCPlot(dTrainV,'pred',yName,
                       paste(mTitle,'train')))
dTestV$pred <- predict(modelV,newdata=dTestV,type='response')
print(paste('test errorRate',errorRate(dTestV$pred,dTestV[[yName]])))
print(WVPlots::ROCPlot(dTestV,'pred',yName,
                       paste(mTitle,'train')))
```

```{r}
print("vtreat cross model")
pruneSig = 0.05
if("mkCrossFrameCExperiment" %in% ls('package:vtreat')) {
  print("working vtreat cross model")
  mTitle <- 'vtreat cross model'
  crossD <- vtreat::mkCrossFrameCExperiment(dTrain,vars,yName,TRUE,
                                            rareSig=0.3,
                                            smFactor=5.0,
                                            minFraction=2.0,
                                            parallelCluster=cl)
  treatments <- crossD$treatments
  dTrainV <- crossD$crossFrame
  
#  print(treatments$scoreFrame)
  varsV <- intersect(colnames(dTrainV),
                     treatments$scoreFrame$varName[treatments$scoreFrame$sig<pruneSig])
  print(varsV)
  dTestV <- vtreat::prepare(treatments,dTest,pruneSig=pruneSig,
                            varRestriction=varsV,
                            parallelCluster=cl)
  formulaV <- paste(yName,paste(varsV,collapse=' + '),sep=' ~ ')
  modelV <- glm(formulaV,data=dTrainV,family=binomial(link='logit'))
  dTrainV$pred <- predict(modelV,newdata=dTrainV,type='response')
  print(paste('train errorRate',errorRate(dTrainV$pred,dTrainV[[yName]])))
  print(WVPlots::ROCPlot(dTrainV,'pred',yName,
                         paste(mTitle,'train')))
  dTestV$pred <- predict(modelV,newdata=dTestV,type='response')
  print(paste('test errorRate',errorRate(dTestV$pred,dTestV[[yName]])))
  print(WVPlots::ROCPlot(dTestV,'pred',yName,
                         paste(mTitle,'test')))
} else {
  print("cross model function not in library")
}
```




```{r}
if(!is.null(cl)) {
  parallel::stopCluster(cl)
  cl <- NULL
}
```
