---
title: "impute"
output: html_document
---



This article is on preparing data for modeling in [R](https://cran.r-project.org) using [`vtreat`](https://CRAN.R-project.org/package=vtreat) and it relation to missing value
imputation.  `vtreat` solves a lot more problems than just missing values (including novel values, and large cardinality categorical variables), but handling of missing values is of course a point of interest.


# `vtreat`: imputation

`vtreat` is a bit different than missing value imputation in that it supplies a
number of other services, and when it does impute missing values (by simple means
estimation) it leaves a mark that such an imputation was applied.  We have found
in practice leaving the information in is very advantageous when values are not simply
"missing at random."  `vtreat` can also be combined with external missing value 
imputation for a combined approach.

![](vtreat.png)

## Our example

Suppose we wish to work with some data.  Our example task is to train a classification model 
for credit approval using the [`ranger`](https://CRAN.R-project.org/package=ranger) implementation of the random forests method.  We will take our data from [John Ross Quinlan's re-processed "credit approval" dataset](https://archive.ics.uci.edu/ml/datasets/Credit+Approval) hosted at
[Lichman, M. (2013). UCI Machine Learning Repository, http://archive.ics.uci.edu/ml; Irvine, CA: University of California, School of Information and Computer Science](http://archive.ics.uci.edu/ml).

For convenience we have copied the data to our working directory [here](https://github.com/WinVector/Examples/tree/master/vtreat).  We start by loading the data, identifying the outcome, and splitting the data into training and evaluation portions:

```{r}
# load data
d <- read.table(
  'crx.data.txt',
  header = FALSE,
  sep = ',',
  stringsAsFactors = FALSE,
  na.strings = '?'
)

# prepare outcome column and level
outcome <- 'V16'
positive <- '+'
d[[outcome]] <- as.factor(d[[outcome]])

# identify variables
vars <- setdiff(colnames(d), outcome)

# split into train and test/evaluation
set.seed(25325)
isTrain <- runif(nrow(d)) <= 0.8
dTrain <- d[isTrain, , drop = FALSE]
dTest <- d[!isTrain, , drop = FALSE]
rm(list = 'd')
```

## Missing value imputation alone.

We could try to model directly on the original variables without `vtreat` as below.

```{r try1, error=TRUE}
library("ranger")
library("mice")
library("dplyr")

dcomb <- rbind(dTrain[, vars, drop=FALSE], 
               dTest[, vars, drop=FALSE])
charCols <- colnames(dcomb)[vapply(dcomb, 
                                   is.character,
                                   logical(1))]
for(ci in charCols) {
  dcomb[[ci]] <- as.factor(dcomb[[ci]])
}
isTrain <- rep(FALSE, nrow(dcomb))
isTrain[seq_len(nrow(dTrain))] <- TRUE
impute <- mice(dcomb, method='rf')
reps <- lapply(seq_len(5),
       function(i) {
         di <- complete(impute, 1)
         di$replication <- i
         dTraini <- di[isTrain, ]
         dTraini[[outcome]] <- dTrain[[outcome]]
         dTraini$origRowNum <- seq_len(nrow(dTrain))
         dTesti <- di[!isTrain, ]
         dTesti$origRowNum <- seq_len(nrow(dTest))
         dTesti[[outcome]] <- dTest[[outcome]]
         data.frame()
         data_frame(train= list(dTraini), 
                    test= list(dTesti))
                                
       })
reps <- bind_rows(reps)
rTrain <- bind_rows(reps$train)
rTest <- bind_rows(reps$test)

f <- paste(outcome, 
           paste(vars, collapse = ' + '), 
           sep = ' ~ ')
model <- ranger(as.formula(f),  
                probability = TRUE,
                data = rTrain)
pred <- predict(model, 
                data=rTest, 
                type='response')
rTest$pred <- pred$predictions[,positive]
rTest %>% 
  group_by(origRowNum) %>%
  summarize(pred = mean(pred)) %>%
  arrange(origRowNum) -> preds
dTest$pred <- preds$pred
```

And we are now ready to examine the model's out of sample performance.
In this case we are going to use ROC/AUC as our evaluation.

```{r eval}
library("WVPlots")
WVPlots::ROCPlot(dTest, 
                 'pred', outcome, positive,
                 'test performance')
```

The imputed model performance is excellent.  The trade-off is the imputed values are probably better replacement values than `vtreat`'s mere means, however `vtreat`'s indication of missingness is a powerful modeling feature that is not to be ignored.

An interesting strategy is to combine the methodologies.

## Combined methodology


